# Roadmap: Datasets & Workspace Management

> **Status**: Draft
> **Version**: 0.1
> **Last Updated**: 2025-01-07
> **Priority**: High (Core Feature)

---

## Overview

This roadmap covers the enhancement of the **Datasets page** and related **Workspace/Settings** functionality. The goal is to transform the current simple dataset linking mechanism into a comprehensive data management system that fully leverages nirs4all's data loading capabilities.

---

## Table of Contents

1. [Current State](#current-state)
2. [Target Vision](#target-vision)
3. [Phase 1: Dataset Loading Wizard](#phase-1-dataset-loading-wizard)
4. [Phase 2: Dataset Versioning & Integrity](#phase-2-dataset-versioning--integrity)
5. [Phase 3: Multi-Target Support](#phase-3-multi-target-support)
6. [Phase 4: Pipeline Integration](#phase-4-pipeline-integration)
7. [Phase 5: Workspace & Settings Improvements](#phase-5-workspace--settings-improvements)
8. [Phase 6: Developer Mode Features](#phase-6-developer-mode-features)
9. [Technical Considerations](#technical-considerations)
10. [Dependencies](#dependencies)

---

## Current State

### What Exists

**Datasets Page (`/datasets`)**
- Simple modal with 2 options: Select Folder or Select Files
- Basic CSV parsing options (delimiter, decimal, header type)
- File type auto-detection (X/Y/metadata) based on filename patterns
- Source assignment for multi-source datasets
- Manual file-to-role mapping
- Dataset groups for organization
- Grid/List view with search and filter

**Workspace API (`/api/workspace`)**
- Create/select/list workspaces
- Link/unlink datasets (path reference)
- Dataset groups CRUD
- Workspace export to archive
- Custom nodes management

**Datasets API (`/api/datasets`)**
- List datasets with status (available/missing)
- Load/refresh dataset info
- Split/filter/merge operations
- Export to CSV/Excel/Parquet/NPZ
- Basic statistics computation

### Current Limitations

1. **Wizard is too simplistic** - Doesn't expose all nirs4all loading capabilities
2. **No versioning** - Can't track if dataset changed on disk
3. **No relinking** - Can't update path when moving between machines
4. **Single target assumption** - UI doesn't handle multiple target columns
5. **No live preview** - Can't see data before confirming
6. **Missing format support** - Excel, MATLAB, NPZ, Parquet not fully exposed in UI
7. **No signal type handling** - Can't specify absorbance/reflectance
8. **No aggregation support** - Can't configure sample aggregation
9. **No workspace statistics** - Can't see space usage

---

## Target Vision

Transform dataset management into a **wizard-based, versioned, multi-target-aware** system that:

1. Guides users through all nirs4all data loading options
2. Tracks dataset integrity with content hashing
3. Allows relinking when paths change
4. Supports multiple targets with selection at runtime
5. Provides live data preview at each configuration step
6. Integrates with Pipeline Editor for data-aware configuration

---

## Phase 1: Dataset Loading Wizard

**Priority**: ðŸ”´ Critical
**Estimated Effort**: Large (2-3 weeks)

### 1.1 Wizard Architecture

Replace the current 2-step modal with a multi-step wizard:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Source Selection                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Folder    â”‚ â”‚   Files     â”‚ â”‚   URL       â”‚ â”‚  Synthetic  â”‚   â”‚
â”‚  â”‚   (auto)    â”‚ â”‚  (manual)   â”‚ â”‚  (remote)   â”‚ â”‚   (gen)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: File Detection & Mapping                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Detected Files          â”‚ Role       â”‚ Split   â”‚ Source      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ train_x.csv    [âœ“ auto] â”‚ Features   â”‚ Train   â”‚ Source 1    â”‚  â”‚
â”‚  â”‚ train_y.csv    [âœ“ auto] â”‚ Targets    â”‚ Train   â”‚ -           â”‚  â”‚
â”‚  â”‚ train_m.csv    [âœ“ auto] â”‚ Metadata   â”‚ Train   â”‚ -           â”‚  â”‚
â”‚  â”‚ test_x.csv     [âœ“ auto] â”‚ Features   â”‚ Test    â”‚ Source 1    â”‚  â”‚
â”‚  â”‚ markers.csv    [+ Add]  â”‚ Features   â”‚ Train   â”‚ Source 2    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  [Preview Data]                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Parsing Configuration                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Global Settings        â”‚ Per-File Overrides                     â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚ Delimiter:    [;  â–¾]   â”‚ train_x.csv:                           â”‚â”‚
â”‚  â”‚ Decimal:      [.  â–¾]   â”‚   â””â”€ Override: [âœ—]                     â”‚â”‚
â”‚  â”‚ Has Header:   [âœ“]      â”‚ markers.csv:                           â”‚â”‚
â”‚  â”‚ Header Unit:  [nm â–¾]   â”‚   â””â”€ Override: [âœ“] Delimiter: [,]      â”‚â”‚
â”‚  â”‚ Signal Type:  [auto â–¾] â”‚                                        â”‚â”‚
â”‚  â”‚ NA Policy:    [drop â–¾] â”‚                                        â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  [Auto-detect] [Preview Parsed Data]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Target & Metadata Configuration                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Target Columns (Y)              â”‚ Metadata Columns              â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚ [âœ“] protein   (numeric)         â”‚ [âœ“] sample_id                 â”‚â”‚
â”‚  â”‚ [âœ“] moisture  (numeric)         â”‚ [âœ“] batch                     â”‚â”‚
â”‚  â”‚ [ ] fiber    (numeric)          â”‚ [âœ“] date                      â”‚â”‚
â”‚  â”‚ Task Type: [regression â–¾]       â”‚ [ ] operator                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Aggregation: [None â–¾] by column: [sample_id â–¾]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Preview & Confirm                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Dataset Summary          â”‚ â”‚ Spectra Preview                    â”‚â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚ Name: wheat_protein      â”‚ â”‚ â”‚     [Line chart of spectra]   â”‚ â”‚â”‚
â”‚  â”‚ Samples: 1,250           â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â”‚ Features: 2,048          â”‚ â”‚                                    â”‚â”‚
â”‚  â”‚ Sources: 2               â”‚ â”‚ Target Distribution                â”‚â”‚
â”‚  â”‚ Targets: 2 (protein,     â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚          moisture)       â”‚ â”‚ â”‚   [Histogram of Y values]     â”‚ â”‚â”‚
â”‚  â”‚ Train: 1,000             â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â”‚ Test: 250                â”‚ â”‚                                    â”‚â”‚
â”‚  â”‚ Hash: a3f7c2...          â”‚ â”‚                                    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                     â”‚
â”‚  [â† Back]                                  [Cancel] [Add Dataset]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Supported Loading Options

Expose all nirs4all `DatasetConfigs` options:

| Option | UI Element | nirs4all Key |
|--------|-----------|--------------|
| Delimiter | Dropdown | `delimiter` |
| Decimal separator | Dropdown | `decimal_separator` |
| Has header | Toggle | `has_header` |
| Header unit | Dropdown | `header_unit` (nm, cm-1, none, text, index) |
| Signal type | Dropdown | `signal_type` (absorbance, reflectance, reflectance%, transmittance, transmittance%, auto) |
| NA policy | Dropdown | `na_policy` (drop, fill_mean, fill_median, fill_zero) |
| Target column | Multi-select | `target_column` |
| Task type | Dropdown | `task_type` (auto, regression, binary_classification, multiclass_classification) |
| Aggregation | Toggle + Dropdown | `aggregate`, `aggregate_method` |
| Sheet name (Excel) | Dropdown | `sheet_name` |

### 1.3 File Format Support

| Format | Extensions | UI Support |
|--------|-----------|------------|
| CSV | `.csv` | âœ… Full config |
| Excel | `.xlsx`, `.xls` | Sheet selector, header row |
| MATLAB | `.mat` | Variable selector |
| NumPy | `.npy`, `.npz` | Array key selector |
| Parquet | `.parquet` | Column selector |

### 1.4 Tasks

- [ ] **T1.1**: Design wizard step components (React)
- [ ] **T1.2**: Create `DatasetWizard` container component
- [ ] **T1.3**: Implement step 1: Source selection with folder/file/URL pickers
- [ ] **T1.4**: Implement step 2: File detection with drag-drop reordering
- [ ] **T1.5**: Implement step 3: Parsing config with global/per-file overrides
- [ ] **T1.6**: Implement step 4: Target and metadata column selection
- [ ] **T1.7**: Implement step 5: Preview with spectra chart and stats
- [ ] **T1.8**: Backend API: `/api/datasets/preview` for parsing preview
- [ ] **T1.9**: Backend API: `/api/datasets/detect-files` for folder scanning
- [ ] **T1.10**: Backend API: `/api/datasets/detect-format` for file format detection
- [ ] **T1.11**: Integrate with existing `link_dataset` with extended config
- [ ] **T1.12**: Add validation at each step with helpful error messages
- [ ] **T1.13**: Store complete loading config in workspace.json

---

## Phase 2: Dataset Versioning & Integrity

**Priority**: ðŸŸ  High
**Estimated Effort**: Medium (1 week)

### 2.1 Content Hashing

Compute a hash of the dataset content to detect changes:

```python
# Backend: datasets.py
def compute_dataset_hash(dataset_path: Path) -> str:
    """Compute SHA-256 hash of dataset files."""
    hasher = hashlib.sha256()
    for file in sorted(dataset_path.glob("**/*")):
        if file.is_file():
            hasher.update(file.read_bytes())
    return hasher.hexdigest()[:16]  # Short hash for display
```

### 2.2 Version States

| State | Icon | Description | Actions |
|-------|------|-------------|---------|
| `current` | âœ… | Hash matches stored hash | - |
| `modified` | âš ï¸ | Hash differs from stored | Refresh, Ignore |
| `missing` | âŒ | Path not accessible | Relink, Remove |
| `unchecked` | â“ | Never verified | Verify |

### 2.3 Refresh Workflow

```
User clicks "Refresh" on modified dataset
           â†“
Backend reloads data, computes new hash
           â†“
Show diff summary: "250 samples added, 3 removed"
           â†“
User confirms â†’ Update stored hash + config
```

### 2.4 Relink Workflow

```
Dataset shows as "missing"
           â†“
User clicks "Relink"
           â†“
File picker opens
           â†“
User selects new path
           â†“
Backend validates structure matches original config
           â†“
If match â†’ Update path, verify hash
If mismatch â†’ Show warning, allow force relink
```

### 2.5 Tasks

- [ ] **T2.1**: Add `hash`, `last_verified`, `version` fields to dataset schema
- [ ] **T2.2**: Compute hash on dataset link
- [ ] **T2.3**: Background hash verification on workspace load
- [ ] **T2.4**: UI: Status badges (current, modified, missing, unchecked)
- [ ] **T2.5**: UI: Refresh confirmation dialog with change summary
- [ ] **T2.6**: UI: Relink dialog with path picker and validation
- [ ] **T2.7**: API: `POST /api/datasets/{id}/verify` - verify hash
- [ ] **T2.8**: API: `POST /api/datasets/{id}/relink` - update path

---

## Phase 3: Multi-Target Support

**Priority**: ðŸŸ  High
**Estimated Effort**: Medium (1 week)

### 3.1 Target Registration

During wizard step 4, users can select **multiple target columns**:

```json
{
  "id": "dataset_123",
  "targets": [
    {"column": "protein", "type": "regression", "unit": "%"},
    {"column": "moisture", "type": "regression", "unit": "%"},
    {"column": "quality", "type": "classification", "classes": ["A", "B", "C"]}
  ],
  "default_target": "protein"
}
```

### 3.2 Target Selection at Runtime

When creating an experiment or in Pipeline Editor, users select which target(s) to use:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Target Selection                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dataset: wheat_samples                      â”‚
â”‚                                             â”‚
â”‚ Available Targets:                          â”‚
â”‚ â—‹ protein (regression, %)                   â”‚
â”‚ â—‹ moisture (regression, %)                  â”‚
â”‚ â—‹ quality (classification, 3 classes)       â”‚
â”‚                                             â”‚
â”‚ [Use dataset default: protein]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Tasks

- [ ] **T3.1**: Update dataset schema to support multiple targets
- [ ] **T3.2**: Wizard step 4: Multi-select for target columns
- [ ] **T3.3**: Store target metadata (type, unit, classes)
- [ ] **T3.4**: Dataset card: Show all targets with types
- [ ] **T3.5**: Experiment wizard: Target selector per dataset
- [ ] **T3.6**: Pipeline Editor: Target selector in dataset binding
- [ ] **T3.7**: Backend: Accept `target_column` param in run/predict

---

## Phase 4: Pipeline Integration

**Priority**: ðŸŸ¡ Medium
**Estimated Effort**: Medium (1 week)

### 4.1 Temporary Dataset Binding in Pipeline Editor

Allow users to "bind" a dataset temporarily to the pipeline being edited. This enables:

- **Presizing**: Show actual feature count for dimension-aware steps
- **Validation**: Warn if pipeline incompatible with data shape
- **Preview**: Run mini-pipeline on subset for visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline Editor                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data Binding: [wheat_protein â–¾] (1000 samples, 2048 features)  â”‚
â”‚               [Clear binding]                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  SNV    â”‚ â†’ â”‚ FirstDerivative â”‚ â†’ â”‚ PLS (10 comp)     â”‚     â”‚
â”‚  â”‚         â”‚    â”‚ window=11     â”‚    â”‚ Max: 2048         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Shape Propagation

Show how data shape changes through the pipeline:

```
Input: (1000, 2048)
  â†“ SNV
(1000, 2048)  # No change
  â†“ FirstDerivative
(1000, 2036)  # Reduced by window-1
  â†“ PLS(10)
(1000, 10)    # Projected to components
```

### 4.3 Tasks

- [ ] **T4.1**: Add "Bind Dataset" dropdown to Pipeline Editor header
- [ ] **T4.2**: Store binding in local state (not saved with pipeline)
- [ ] **T4.3**: Pass bound dataset info to step components
- [ ] **T4.4**: Show sample/feature counts next to binding
- [ ] **T4.5**: Shape propagation calculator
- [ ] **T4.6**: Display shape changes in pipeline tree
- [ ] **T4.7**: Warn when step params exceed data dimensions

---

## Phase 5: Workspace & Settings Improvements

**Priority**: ðŸŸ¡ Medium
**Estimated Effort**: Small (3-5 days)

### 5.1 Workspace Statistics

Add statistics card to Settings page:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workspace Statistics                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Path: /home/user/nirs_workspace             â”‚
â”‚                                             â”‚
â”‚ Space Usage:                                â”‚
â”‚ â”œâ”€ Results:     45.2 MB  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 45%    â”‚
â”‚ â”œâ”€ Models:      32.1 MB  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 32%    â”‚
â”‚ â”œâ”€ Predictions: 18.7 MB  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 19%    â”‚
â”‚ â”œâ”€ Pipelines:    4.0 MB  â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4%    â”‚
â”‚ â””â”€ Total:      100.0 MB                     â”‚
â”‚                                             â”‚
â”‚ Linked Datasets: 12 (external storage)      â”‚
â”‚ Last Backup: 2025-01-05 14:30               â”‚
â”‚                                             â”‚
â”‚ [Clean Cache] [Backup Now] [Export Archive] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Settings Organization

Move dataset-related settings to a dedicated section:

```
Settings Page
â”œâ”€â”€ General
â”‚   â”œâ”€â”€ Theme (Light/Dark/System)
â”‚   â””â”€â”€ Language (en, fr, de)
â”œâ”€â”€ Workspace
â”‚   â”œâ”€â”€ Current workspace path
â”‚   â”œâ”€â”€ Statistics (as above)
â”‚   â”œâ”€â”€ Recent workspaces list
â”‚   â””â”€â”€ Create new workspace
â”œâ”€â”€ Data Defaults
â”‚   â”œâ”€â”€ Default delimiter
â”‚   â”œâ”€â”€ Default decimal separator
â”‚   â”œâ”€â”€ Default header unit
â”‚   â”œâ”€â”€ Default signal type
â”‚   â””â”€â”€ Auto-detect settings
â””â”€â”€ Advanced
    â”œâ”€â”€ Backend URL
    â”œâ”€â”€ Cache settings
    â””â”€â”€ Developer mode toggle
```

### 5.3 Tasks

- [ ] **T5.1**: API: `GET /api/workspace/stats` - compute space usage
- [ ] **T5.2**: UI: Space usage visualization with progress bars
- [ ] **T5.3**: UI: Clean cache action with confirmation
- [ ] **T5.4**: UI: Reorganize Settings page sections
- [ ] **T5.5**: Store data loading defaults in workspace config
- [ ] **T5.6**: Apply defaults in wizard, allow override

---

## Phase 6: Developer Mode Features

**Priority**: ðŸŸ¢ Low
**Estimated Effort**: Small (2-3 days)

### 6.1 Synthetic Dataset Generation

In developer mode, Dashboard quick actions include generating synthetic datasets:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Developer Quick Start                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Generate Synthetic Dataset:                 â”‚
â”‚                                             â”‚
â”‚ â—‹ Regression (250 samples)                  â”‚
â”‚ â—‹ Regression (2500 samples)                 â”‚
â”‚ â—‹ Classification (300 samples, 3 classes)   â”‚
â”‚ â—‹ Custom...                                 â”‚
â”‚                                             â”‚
â”‚ Options:                                    â”‚
â”‚ [âœ“] Include repetitions                     â”‚
â”‚ [âœ“] Include metadata                        â”‚
â”‚ [âœ“] Add noise                               â”‚
â”‚                                             â”‚
â”‚ [Generate & Load]                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 nirs4all.generate Integration

Use nirs4all's synthesis tools:

```python
# Backend: dashboard.py or datasets.py
@router.post("/datasets/generate-synthetic")
async def generate_synthetic(
    task_type: str = "regression",
    n_samples: int = 500,
    n_features: int = 256,
    include_repetitions: bool = True,
    include_metadata: bool = True,
    noise_level: float = 0.05,
):
    import nirs4all

    if task_type == "regression":
        dataset = nirs4all.generate.regression(
            n_samples=n_samples,
            n_features=n_features,
            ...
        )
    elif task_type == "classification":
        dataset = nirs4all.generate.classification(
            n_samples=n_samples,
            n_features=n_features,
            n_classes=3,
            ...
        )

    # Save to workspace as temporary dataset
    # Return dataset info for immediate use
```

### 6.3 Tasks

- [ ] **T6.1**: Add developer mode toggle in Settings
- [ ] **T6.2**: Conditional UI for developer mode features
- [ ] **T6.3**: API: `/api/datasets/generate-synthetic`
- [ ] **T6.4**: Dashboard: Synthetic data generation card
- [ ] **T6.5**: Options for repetitions, metadata, noise
- [ ] **T6.6**: Auto-link generated dataset to workspace

---

## Technical Considerations

### API Changes Summary

| Endpoint | Method | Description | Phase |
|----------|--------|-------------|-------|
| `/api/datasets/preview` | POST | Preview parsed data | 1 |
| `/api/datasets/detect-files` | POST | Scan folder for data files | 1 |
| `/api/datasets/detect-format` | POST | Detect file format | 1 |
| `/api/datasets/{id}/verify` | POST | Verify dataset hash | 2 |
| `/api/datasets/{id}/relink` | POST | Update dataset path | 2 |
| `/api/workspace/stats` | GET | Workspace space usage | 5 |
| `/api/datasets/generate-synthetic` | POST | Generate synthetic data | 6 |

### Schema Changes

**Dataset in workspace.json**:
```json
{
  "id": "uuid",
  "name": "wheat_protein",
  "path": "/data/wheat",
  "hash": "a3f7c2e9",
  "last_verified": "2025-01-07T10:30:00Z",
  "version": 1,
  "config": {
    "train_x": "train_x.csv",
    "train_y": "train_y.csv",
    "train_x_params": {
      "delimiter": ";",
      "header_unit": "nm",
      "signal_type": "reflectance"
    },
    "global_params": {
      "na_policy": "drop"
    }
  },
  "targets": [
    {"column": "protein", "type": "regression", "unit": "%"},
    {"column": "moisture", "type": "regression", "unit": "%"}
  ],
  "default_target": "protein",
  "num_samples": 1250,
  "num_features": 2048,
  "status": "current",
  "group": "project_wheat"
}
```

### Component Structure

```
src/components/datasets/
â”œâ”€â”€ AddDatasetModal.tsx      â†’ DEPRECATED (replace with wizard)
â”œâ”€â”€ DatasetWizard/
â”‚   â”œâ”€â”€ index.tsx            # Wizard container
â”‚   â”œâ”€â”€ WizardContext.tsx    # State management
â”‚   â”œâ”€â”€ SourceStep.tsx       # Step 1
â”‚   â”œâ”€â”€ FileMappingStep.tsx  # Step 2
â”‚   â”œâ”€â”€ ParsingStep.tsx      # Step 3
â”‚   â”œâ”€â”€ TargetsStep.tsx      # Step 4
â”‚   â”œâ”€â”€ PreviewStep.tsx      # Step 5
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ FileTable.tsx
â”‚       â”œâ”€â”€ ParsingOptions.tsx
â”‚       â”œâ”€â”€ TargetSelector.tsx
â”‚       â””â”€â”€ DataPreview.tsx
â”œâ”€â”€ DatasetCard.tsx          # Enhanced with status badge
â”œâ”€â”€ DatasetStatusBadge.tsx   # NEW: Version status indicator
â”œâ”€â”€ RelinkDialog.tsx         # NEW: Path update dialog
â”œâ”€â”€ RefreshDialog.tsx        # NEW: Change summary dialog
â””â”€â”€ index.ts
```

---

## Dependencies

### Phase Dependencies

```
Phase 1 (Wizard) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â†“                                           â†“
Phase 2 (Versioning) â”€â”€â”€â”€â”€â”´â”€â”€â†’ Phase 3 (Multi-Target) â”€â”€â†’ Phase 4 (Pipeline)
                                                                      â†“
Phase 5 (Settings) â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
Phase 6 (Dev Mode) â†â”€â”€â”€â”€â”€â”€â”˜
```

### External Dependencies

- **nirs4all**: All data loading functionality
- **pywebview**: Native file dialogs (desktop mode)
- **recharts**: Data preview charts
- **shadcn/ui**: UI components

---

## Success Metrics

| Metric | Target |
|--------|--------|
| Dataset loading success rate | > 95% |
| Average wizard completion time | < 3 minutes |
| User confusion (support tickets) | < 5% of users |
| Dataset format support coverage | 100% of nirs4all formats |

---

## Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 0.1 | 2025-01-07 | Copilot | Initial draft from UI_SPECIFICATION annotations |

