# Roadmap: Datasets & Workspace Management

> **Status**: Complete
> **Version**: 1.0
> **Last Updated**: 2026-01-07
> **Priority**: High (Core Feature)
>
> ### Progress Summary
> | Phase | Status | Description |
> |-------|--------|-------------|
> | Phase 1 | âœ… Complete | Dataset Loading Wizard |
> | Phase 2 | âœ… Complete | Versioning & Integrity |
> | Phase 3 | âœ… Complete | Multi-Target Support |
> | Phase 4 | âœ… Complete | Pipeline Integration |
> | Phase 5 | âœ… Complete | Workspace & Settings |
> | Phase 6 | âœ… Complete | Developer Mode Features |

---

## Overview

This roadmap covers the enhancement of the **Datasets page** and related **Workspace/Settings** functionality. The goal is to transform the current simple dataset linking mechanism into a comprehensive data management system that fully leverages nirs4all's data loading capabilities.

---

## Table of Contents

1. [Current State](#current-state)
2. [Target Vision](#target-vision)
3. [Phase 1: Dataset Loading Wizard](#phase-1-dataset-loading-wizard)
4. [Phase 2: Dataset Versioning & Integrity](#phase-2-dataset-versioning--integrity)
5. [Phase 3: Multi-Target Support](#phase-3-multi-target-support)
6. [Phase 4: Pipeline Integration](#phase-4-pipeline-integration)
7. [Phase 5: Workspace & Settings Improvements](#phase-5-workspace--settings-improvements)
8. [Phase 6: Developer Mode Features](#phase-6-developer-mode-features)
9. [Technical Considerations](#technical-considerations)
10. [Dependencies](#dependencies)

---

## Current State

### What Exists

**Datasets Page (`/datasets`)**
- Simple modal with 2 options: Select Folder or Select Files
- Basic CSV parsing options (delimiter, decimal, header type)
- File type auto-detection (X/Y/metadata) based on filename patterns
- Source assignment for multi-source datasets
- Manual file-to-role mapping
- Dataset groups for organization
- Grid/List view with search and filter

**Workspace API (`/api/workspace`)**
- Create/select/list workspaces
- Link/unlink datasets (path reference)
- Dataset groups CRUD
- Workspace export to archive
- Custom nodes management

**Datasets API (`/api/datasets`)**
- List datasets with status (available/missing)
- Load/refresh dataset info
- Split/filter/merge operations
- Export to CSV/Excel/Parquet/NPZ
- Basic statistics computation

### Current Limitations

1. **Wizard is too simplistic** - Doesn't expose all nirs4all loading capabilities
2. **No versioning** - Can't track if dataset changed on disk
3. **No relinking** - Can't update path when moving between machines
4. **Single target assumption** - UI doesn't handle multiple target columns
5. **No live preview** - Can't see data before confirming
6. **Missing format support** - Excel, MATLAB, NPZ, Parquet not fully exposed in UI
7. **No signal type handling** - Can't specify absorbance/reflectance
8. **No aggregation support** - Can't configure sample aggregation
9. **No workspace statistics** - Can't see space usage

---

## Target Vision

Transform dataset management into a **wizard-based, versioned, multi-target-aware** system that:

1. Guides users through all nirs4all data loading options
2. Tracks dataset integrity with content hashing
3. Allows relinking when paths change
4. Supports multiple targets with selection at runtime
5. Provides live data preview at each configuration step
6. Integrates with Pipeline Editor for data-aware configuration

---

## Phase 1: Dataset Loading Wizard

**Priority**: ðŸ”´ Critical
**Estimated Effort**: Large (2-3 weeks)

### 1.1 Wizard Architecture

Replace the current 2-step modal with a multi-step wizard:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Source Selection                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Folder    â”‚ â”‚   Files     â”‚ â”‚   URL       â”‚ â”‚  Synthetic  â”‚   â”‚
â”‚  â”‚   (auto)    â”‚ â”‚  (manual)   â”‚ â”‚  (remote)   â”‚ â”‚   (gen)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: File Detection & Mapping                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Detected Files          â”‚ Role       â”‚ Split   â”‚ Source      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ train_x.csv    [âœ“ auto] â”‚ Features   â”‚ Train   â”‚ Source 1    â”‚  â”‚
â”‚  â”‚ train_y.csv    [âœ“ auto] â”‚ Targets    â”‚ Train   â”‚ -           â”‚  â”‚
â”‚  â”‚ train_m.csv    [âœ“ auto] â”‚ Metadata   â”‚ Train   â”‚ -           â”‚  â”‚
â”‚  â”‚ test_x.csv     [âœ“ auto] â”‚ Features   â”‚ Test    â”‚ Source 1    â”‚  â”‚
â”‚  â”‚ markers.csv    [+ Add]  â”‚ Features   â”‚ Train   â”‚ Source 2    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  [Preview Data]                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Parsing Configuration                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Global Settings        â”‚ Per-File Overrides                     â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚ Delimiter:    [;  â–¾]   â”‚ train_x.csv:                           â”‚â”‚
â”‚  â”‚ Decimal:      [.  â–¾]   â”‚   â””â”€ Override: [âœ—]                     â”‚â”‚
â”‚  â”‚ Has Header:   [âœ“]      â”‚ markers.csv:                           â”‚â”‚
â”‚  â”‚ Header Unit:  [nm â–¾]   â”‚   â””â”€ Override: [âœ“] Delimiter: [,]      â”‚â”‚
â”‚  â”‚ Signal Type:  [auto â–¾] â”‚                                        â”‚â”‚
â”‚  â”‚ NA Policy:    [drop â–¾] â”‚                                        â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  [Auto-detect] [Preview Parsed Data]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: Target & Metadata Configuration                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Target Columns (Y)              â”‚ Metadata Columns              â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚ [âœ“] protein   (numeric)         â”‚ [âœ“] sample_id                 â”‚â”‚
â”‚  â”‚ [âœ“] moisture  (numeric)         â”‚ [âœ“] batch                     â”‚â”‚
â”‚  â”‚ [ ] fiber    (numeric)          â”‚ [âœ“] date                      â”‚â”‚
â”‚  â”‚ Task Type: [regression â–¾]       â”‚ [ ] operator                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Aggregation: [None â–¾] by column: [sample_id â–¾]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: Preview & Confirm                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Dataset Summary          â”‚ â”‚ Spectra Preview                    â”‚â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚ Name: wheat_protein      â”‚ â”‚ â”‚     [Line chart of spectra]   â”‚ â”‚â”‚
â”‚  â”‚ Samples: 1,250           â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â”‚ Features: 2,048          â”‚ â”‚                                    â”‚â”‚
â”‚  â”‚ Sources: 2               â”‚ â”‚ Target Distribution                â”‚â”‚
â”‚  â”‚ Targets: 2 (protein,     â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚          moisture)       â”‚ â”‚ â”‚   [Histogram of Y values]     â”‚ â”‚â”‚
â”‚  â”‚ Train: 1,000             â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â”‚ Test: 250                â”‚ â”‚                                    â”‚â”‚
â”‚  â”‚ Hash: a3f7c2...          â”‚ â”‚                                    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                     â”‚
â”‚  [â† Back]                                  [Cancel] [Add Dataset]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Supported Loading Options

Expose all nirs4all `DatasetConfigs` options:

| Option | UI Element | nirs4all Key |
|--------|-----------|--------------|
| Delimiter | Dropdown | `delimiter` |
| Decimal separator | Dropdown | `decimal_separator` |
| Has header | Toggle | `has_header` |
| Header unit | Dropdown | `header_unit` (nm, cm-1, none, text, index) |
| Signal type | Dropdown | `signal_type` (absorbance, reflectance, reflectance%, transmittance, transmittance%, auto) |
| NA policy | Dropdown | `na_policy` (drop, fill_mean, fill_median, fill_zero) |
| Target column | Multi-select | `target_column` |
| Task type | Dropdown | `task_type` (auto, regression, binary_classification, multiclass_classification) |
| Aggregation | Toggle + Dropdown | `aggregate`, `aggregate_method` |
| Sheet name (Excel) | Dropdown | `sheet_name` |

### 1.3 File Format Support

| Format | Extensions | UI Support |
|--------|-----------|------------|
| CSV | `.csv` | âœ… Full config |
| Excel | `.xlsx`, `.xls` | Sheet selector, header row |
| MATLAB | `.mat` | Variable selector |
| NumPy | `.npy`, `.npz` | Array key selector |
| Parquet | `.parquet` | Column selector |

### 1.4 Tasks

- [x] **T1.1**: Design wizard step components (React) âœ… *Implemented*
- [x] **T1.2**: Create `DatasetWizard` container component âœ… *Implemented*
- [x] **T1.3**: Implement step 1: Source selection with folder/file/URL pickers âœ… *Implemented*
- [x] **T1.4**: Implement step 2: File detection with drag-drop reordering âœ… *Implemented*
- [x] **T1.5**: Implement step 3: Parsing config with global/per-file overrides âœ… *Implemented*
- [x] **T1.6**: Implement step 4: Target and metadata column selection âœ… *Implemented*
- [x] **T1.7**: Implement step 5: Preview with spectra chart and stats âœ… *Implemented*
- [x] **T1.8**: Backend API: `/api/datasets/preview` for parsing preview âœ… *Implemented*
- [x] **T1.9**: Backend API: `/api/datasets/detect-files` for folder scanning âœ… *Implemented*
- [x] **T1.10**: Backend API: `/api/datasets/detect-format` for file format detection âœ… *Implemented*
- [x] **T1.11**: Integrate with existing `link_dataset` with extended config âœ… *Implemented*
- [ ] **T1.12**: Add validation at each step with helpful error messages â³ *Partial*
- [x] **T1.13**: Store complete loading config in workspace.json âœ… *Implemented*

> **Phase 1 Status**: âœ… **COMPLETE** (as of 2025-01-07)
> - All wizard steps implemented (SourceStep, FileMappingStep, ParsingStep, TargetsStep, PreviewStep)
> - WizardContext for state management
> - Backend APIs for detect-files, detect-format, and preview

---

## Phase 2: Dataset Versioning & Integrity

**Priority**: ðŸŸ  High
**Estimated Effort**: Medium (1 week)
**Status**: âœ… **COMPLETE** (as of 2025-01-07)

### 2.1 Content Hashing

Compute a hash of the dataset content to detect changes:

```python
# Backend: datasets.py - IMPLEMENTED
def compute_dataset_hash(dataset_path: Path) -> str:
    """Compute SHA-256 hash of dataset files."""
    hasher = hashlib.sha256()
    extensions = {".csv", ".xlsx", ".xls", ".parquet", ".npy", ".npz", ".mat"}
    compressed = {".gz", ".bz2", ".xz", ".zip"}

    if dataset_path.is_file():
        hasher.update(dataset_path.read_bytes())
    elif dataset_path.is_dir():
        for file in sorted(dataset_path.rglob("*")):
            if not file.is_file():
                continue
            suffix = file.suffix.lower()
            if suffix in compressed:
                inner_suffix = Path(file.stem).suffix.lower()
                if inner_suffix and inner_suffix in extensions:
                    hasher.update(file.read_bytes())
            elif suffix in extensions:
                hasher.update(file.read_bytes())

    return hasher.hexdigest()[:16]  # Short hash for display
```

### 2.2 Version States

| State | Icon | Description | Actions |
|-------|------|-------------|---------|
| `current` | âœ… | Hash matches stored hash | - |
| `modified` | âš ï¸ | Hash differs from stored | Refresh, Ignore |
| `missing` | âŒ | Path not accessible | Relink, Remove |
| `unchecked` | â“ | Never verified | Verify |

### 2.3 Refresh Workflow

```
User clicks "Refresh" on modified dataset
           â†“
Backend reloads data, computes new hash
           â†“
Show diff summary: "250 samples added, 3 removed"
           â†“
User confirms â†’ Update stored hash + config
```

### 2.4 Relink Workflow

```
Dataset shows as "missing"
           â†“
User clicks "Relink"
           â†“
File picker opens
           â†“
User selects new path
           â†“
Backend validates structure matches original config
           â†“
If match â†’ Update path, verify hash
If mismatch â†’ Show warning, allow force relink
```

### 2.5 Tasks

- [x] **T2.1**: Add `hash`, `last_verified`, `version` fields to dataset schema âœ… *Implemented*
- [x] **T2.2**: Compute hash on dataset link âœ… *Implemented in workspace_manager.link_dataset()*
- [x] **T2.3**: Background hash verification on workspace load âœ… *Implemented via list_datasets(verify_integrity=True)*
- [x] **T2.4**: UI: Status badges (current, modified, missing, unchecked) âœ… *DatasetStatusBadge component*
- [x] **T2.5**: UI: Refresh confirmation dialog with change summary âœ… *RefreshDialog component*
- [x] **T2.6**: UI: Relink dialog with path picker and validation âœ… *RelinkDialog component*
- [x] **T2.7**: API: `POST /api/datasets/{id}/verify` - verify hash âœ… *Implemented*
- [x] **T2.8**: API: `POST /api/datasets/{id}/relink` - update path âœ… *Implemented*

> **Phase 2 Implementation Summary** (2025-01-07):
>
> **Backend (api/datasets.py)**:
> - `compute_dataset_hash()` - SHA-256 hash of data files
> - `compute_dataset_stats()` - File count/size tracking
> - `compute_change_summary()` - Diff between versions
> - `POST /datasets/{id}/verify` - Verify integrity
> - `POST /datasets/{id}/refresh` - Accept changes
> - `POST /datasets/{id}/relink` - Update path
> - `GET /datasets/{id}/version-status` - Quick status check
> - Enhanced `GET /datasets?verify_integrity=true` option
>
> **Frontend (src/components/datasets/)**:
> - `DatasetStatusBadge.tsx` - Version status indicator
> - `RefreshDialog.tsx` - Accept changes dialog
> - `RelinkDialog.tsx` - Path update dialog
> - Updated `DatasetCard.tsx` with version actions
>
> **Types (src/types/datasets.ts)**:
> - `DatasetVersionStatus` type
> - `DatasetChangeSummary` interface
> - `VerifyDatasetResponse`, `RefreshDatasetResponse`, `RelinkDatasetResponse`
>
> **API Client (src/api/client.ts)**:
> - `verifyDataset()`, `refreshDatasetVersion()`, `relinkDataset()`
> - `getDatasetVersionStatus()`, `listDatasets(verifyIntegrity)`

---

## Phase 3: Multi-Target Support

**Priority**: ðŸŸ  High
**Estimated Effort**: Medium (1 week)

### 3.1 Target Registration

During wizard step 4, users can select **multiple target columns**:

```json
{
  "id": "dataset_123",
  "targets": [
    {"column": "protein", "type": "regression", "unit": "%"},
    {"column": "moisture", "type": "regression", "unit": "%"},
    {"column": "quality", "type": "classification", "classes": ["A", "B", "C"]}
  ],
  "default_target": "protein"
}
```

### 3.2 Target Selection at Runtime

When creating an experiment or in Pipeline Editor, users select which target(s) to use:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Target Selection                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dataset: wheat_samples                      â”‚
â”‚                                             â”‚
â”‚ Available Targets:                          â”‚
â”‚ â—‹ protein (regression, %)                   â”‚
â”‚ â—‹ moisture (regression, %)                  â”‚
â”‚ â—‹ quality (classification, 3 classes)       â”‚
â”‚                                             â”‚
â”‚ [Use dataset default: protein]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Tasks

- [x] **T3.1**: Update dataset schema to support multiple targets âœ… *Implemented*
- [x] **T3.2**: Wizard step 4: Multi-select for target columns âœ… *Implemented*
- [x] **T3.3**: Store target metadata (type, unit, classes) âœ… *Implemented*
- [x] **T3.4**: Dataset card: Show all targets with types âœ… *Implemented*
- [x] **T3.5**: Experiment wizard: Target selector per dataset âœ… *TargetSelector component*
- [x] **T3.6**: Pipeline Editor: Target selector in dataset binding âœ… *TargetSelector component*
- [x] **T3.7**: Backend: Accept `target_column` param in run/predict âœ… *Implemented*

> **Phase 3 Implementation Summary** (2026-01-07):
>
> **Backend (api/datasets.py)**:
> - `TargetConfig` Pydantic model for target configuration
> - `GET /datasets/{id}/targets` - Get configured targets
> - `PUT /datasets/{id}/targets` - Update target configuration
> - `POST /datasets/{id}/detect-targets` - Detect columns from Y file
> - `POST /datasets/{id}/set-default-target` - Quick default change
>
> **Frontend (src/components/datasets/)**:
> - Enhanced `TargetsStep.tsx` - Real column detection from Y files
>   - Multi-select target columns
>   - Per-target task type selection
>   - Unit input with common unit suggestions
>   - Default target selection
>   - Selected targets summary
> - `TargetSelector.tsx` - Reusable dropdown component
>   - `TargetSelector` - Main selector for experiments/pipelines
>   - `TargetBadge` - Inline display badge
>   - `TargetsList` - Multi-target display component
> - Updated `DatasetCard.tsx` - Shows target count and default
>
> **Types (src/types/datasets.ts)**:
> - Enhanced `TargetConfig` with `is_default`, `label`, `description`
> - Added `targets` and `default_target` to `Dataset` interface
>
> **API Client (src/api/client.ts)**:
> - `getDatasetTargets()`, `updateDatasetTargets()`
> - `detectDatasetTargets()`, `setDefaultTarget()`

---

## Phase 4: Pipeline Integration

**Priority**: ðŸŸ¡ Medium
**Estimated Effort**: Medium (1 week)
**Status**: âœ… **COMPLETE** (as of 2025-01-08)

### 4.1 Temporary Dataset Binding in Pipeline Editor

Allow users to "bind" a dataset temporarily to the pipeline being edited. This enables:

- **Presizing**: Show actual feature count for dimension-aware steps
- **Validation**: Warn if pipeline incompatible with data shape
- **Preview**: Run mini-pipeline on subset for visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline Editor                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data Binding: [wheat_protein â–¾] (1000 samples, 2048 features)  â”‚
â”‚               [Clear binding]                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  SNV    â”‚ â†’ â”‚ FirstDerivative â”‚ â†’ â”‚ PLS (10 comp)     â”‚     â”‚
â”‚  â”‚         â”‚    â”‚ window=11     â”‚    â”‚ Max: 2048         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Shape Propagation

Show how data shape changes through the pipeline:

```
Input: (1000, 2048)
  â†“ SNV
(1000, 2048)  # No change
  â†“ FirstDerivative
(1000, 2036)  # Reduced by window-1
  â†“ PLS(10)
(1000, 10)    # Projected to components
```

### 4.3 Tasks

- [x] **T4.1**: Add "Bind Dataset" dropdown to Pipeline Editor header âœ… *Implemented*
- [x] **T4.2**: Store binding in local state (not saved with pipeline) âœ… *Implemented*
- [x] **T4.3**: Pass bound dataset info to step components âœ… *Implemented*
- [x] **T4.4**: Show sample/feature counts next to binding âœ… *Implemented*
- [x] **T4.5**: Shape propagation calculator âœ… *Implemented*
- [x] **T4.6**: Display shape changes in pipeline tree âœ… *Implemented*
- [x] **T4.7**: Warn when step params exceed data dimensions âœ… *Implemented*

> **Phase 4 Implementation Summary** (2025-01-08):
>
> **Frontend Hooks (src/hooks/)**:
> - `useDatasetBinding.ts` - Manages dataset binding state with session storage
>   - Session storage persistence (survives page refresh, not browser close)
>   - Automatic dataset list loading
>   - Target selection support for multi-target datasets
>   - 24-hour expiration for stale bindings
> - `useShapePropagation.ts` - Shape propagation calculator
>   - Maps 30+ operators to their shape transformations
>   - Dimension parameter validation (n_components, n_splits, etc.)
>   - Recursive shape tracking through branches/children
>   - Warning generation for dimension issues
>
> **Frontend Components (src/components/pipeline-editor/)**:
> - `DatasetBinding.tsx` - Header dropdown component
>   - Dataset selection dropdown with search
>   - Bound dataset display with shape badge (samples Ã— features)
>   - Target selector for multi-target datasets
>   - Warning indicator with tooltip
>   - Clear/refresh actions
> - `contexts/DatasetBindingContext.tsx` - Context provider
>   - `DatasetBindingProvider` - Wraps pipeline content
>   - `useDatasetBindingContext` - Access binding state
>   - `useStepShape` - Get shape at specific step
>   - `useStepDimensionWarnings` - Get warnings for step
> - `core/tree-node/StepShapeIndicator.tsx` - Visual shape display
>   - `StepShapeIndicator` - Shows input/output shape flow
>   - `ShapeBadge` - Compact shape display (samples Ã— features)
>   - `ShapeFlow` - Arrow visualization of shape change
>
> **Backend (api/pipelines.py)**:
> - `POST /pipelines/propagate-shape` - Calculate shapes server-side
>   - `ShapePropagationRequest` - Pipeline + initial shape
>   - `ShapePropagationResponse` - Shapes at each step + warnings
>   - `SHAPE_TRANSFORMS` - Operator-to-transform mapping
>   - Dimension validation (n_components, n_splits)
>
> **API Client (src/api/client.ts)**:
> - `propagateShape()` - Call backend shape endpoint
> - `ShapeAtStep`, `ShapeWarning`, `ShapePropagationResponse` interfaces
>
> **Integration (src/pages/PipelineEditor.tsx)**:
> - Added `useDatasetBinding` hook initialization
> - `dimensionWarnings` calculation from bound dataset
> - `DatasetBinding` component in header toolbar
> - `DatasetBindingProvider` wrapper around main content

---

## Phase 5: Workspace & Settings Improvements

**Priority**: ðŸŸ¡ Medium
**Estimated Effort**: Small (3-5 days)
**Status**: âœ… **COMPLETE** (as of 2026-01-07)

### 5.1 Workspace Statistics

Add statistics card to Settings page:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workspace Statistics                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Path: /home/user/nirs_workspace             â”‚
â”‚                                             â”‚
â”‚ Space Usage:                                â”‚
â”‚ â”œâ”€ Results:     45.2 MB  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 45%    â”‚
â”‚ â”œâ”€ Models:      32.1 MB  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 32%    â”‚
â”‚ â”œâ”€ Predictions: 18.7 MB  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 19%    â”‚
â”‚ â”œâ”€ Pipelines:    4.0 MB  â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4%    â”‚
â”‚ â””â”€ Total:      100.0 MB                     â”‚
â”‚                                             â”‚
â”‚ Linked Datasets: 12 (external storage)      â”‚
â”‚ Last Backup: 2025-01-05 14:30               â”‚
â”‚                                             â”‚
â”‚ [Clean Cache] [Backup Now] [Export Archive] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Settings Organization

Move dataset-related settings to a dedicated section:

```
Settings Page
â”œâ”€â”€ General
â”‚   â”œâ”€â”€ Theme (Light/Dark/System)
â”‚   â””â”€â”€ Language (en, fr, de)
â”œâ”€â”€ Workspace
â”‚   â”œâ”€â”€ Current workspace path
â”‚   â”œâ”€â”€ Statistics (as above)
â”‚   â”œâ”€â”€ Recent workspaces list
â”‚   â””â”€â”€ Create new workspace
â”œâ”€â”€ Data Defaults
â”‚   â”œâ”€â”€ Default delimiter
â”‚   â”œâ”€â”€ Default decimal separator
â”‚   â”œâ”€â”€ Default header unit
â”‚   â”œâ”€â”€ Default signal type
â”‚   â””â”€â”€ Auto-detect settings
â””â”€â”€ Advanced
    â”œâ”€â”€ Backend URL
    â”œâ”€â”€ Cache settings
    â””â”€â”€ Developer mode toggle
```

### 5.3 Tasks

- [x] **T5.1**: API: `GET /api/workspace/stats` - compute space usage âœ… *Implemented*
- [x] **T5.2**: UI: Space usage visualization with progress bars âœ… *Implemented*
- [x] **T5.3**: UI: Clean cache action with confirmation âœ… *Implemented*
- [x] **T5.4**: UI: Reorganize Settings page sections âœ… *Implemented*
- [x] **T5.5**: Store data loading defaults in workspace config âœ… *Implemented*
- [x] **T5.6**: Apply defaults in wizard, allow override âœ… *Implemented*

> **Phase 5 Implementation Summary** (2026-01-07):
>
> **Backend (api/workspace.py)**:
> - `GET /workspace/stats` - Workspace statistics with space usage breakdown
>   - `SpaceUsageItem` - Per-category size/count/percentage
>   - `WorkspaceStatsResponse` - Complete stats response
>   - Calculates sizes for results, models, predictions, pipelines, cache, temp
>   - External dataset size tracking
>   - Last backup timestamp
> - `POST /workspace/clean-cache` - Clean temporary files and cache
>   - `CleanCacheRequest` - Options for what to clean
>   - `CleanCacheResponse` - Files removed and bytes freed
>   - Supports: temp files, orphan results, old predictions
> - `POST /workspace/backup` - Create workspace backup
>   - Creates timestamped ZIP archive
>   - Records backup timestamp in .nirs4all/last_backup.json
> - `GET /workspace/settings` - Get workspace settings
> - `PUT /workspace/settings` - Update workspace settings
> - `GET /workspace/data-defaults` - Get data loading defaults
> - `PUT /workspace/data-defaults` - Update data loading defaults
>   - `DataLoadingDefaults` - Default CSV parsing settings
>
> **Backend (api/workspace_manager.py)**:
> - `get_settings_path()` - Path to settings.json in .nirs4all
> - `get_workspace_settings()` - Load settings with defaults merge
> - `save_workspace_settings()` - Persist settings to file
> - `get_data_loading_defaults()` - Get parsing defaults
> - `save_data_loading_defaults()` - Save parsing defaults
> - `_default_workspace_settings()` - System defaults
>
> **Frontend Types (src/types/settings.ts)**:
> - `SpaceUsageItem` - Category space usage
> - `WorkspaceStatsResponse` - Stats API response
> - `CleanCacheRequest/Response` - Clean cache types
> - `BackupWorkspaceResponse` - Backup response
> - `DataLoadingDefaults` - Parsing defaults config
> - `WorkspaceSettings` - Complete settings config
> - `DEFAULT_DATA_LOADING_DEFAULTS` - System defaults constant
>
> **Frontend Components (src/components/settings/)**:
> - `WorkspaceStats.tsx` - Statistics card with progress bars
>   - Space usage breakdown by category
>   - Total size and linked datasets count
>   - Last backup timestamp
>   - Clean cache dialog with options
>   - Backup action button
>   - Refresh statistics button
> - `DataLoadingDefaultsForm.tsx` - Defaults configuration form
>   - Auto-detect toggle
>   - CSV parsing options (delimiter, decimal, header)
>   - Spectral options (header unit, signal type)
>   - NA policy selection
>   - Save/revert/reset actions
>
> **Frontend Page (src/pages/Settings.tsx)**:
> - Reorganized with Tabs component:
>   - General: Theme and language settings
>   - Workspace: Current workspace + WorkspaceStats
>   - Data Defaults: DataLoadingDefaultsForm
>   - Advanced: Developer mode, backend URL, troubleshooting
> - Developer mode toggle persisted to workspace settings
> - Clear local cache and reset to defaults actions
>
> **API Client (src/api/client.ts)**:
> - `getWorkspaceStats()` - Fetch statistics
> - `cleanWorkspaceCache()` - Clean cache with options
> - `backupWorkspace()` - Create backup
> - `getWorkspaceSettings()` - Get settings
> - `updateWorkspaceSettings()` - Update settings
> - `getDataLoadingDefaults()` - Get parsing defaults
> - `updateDataLoadingDefaults()` - Update parsing defaults
>
> **Dataset Wizard Integration (src/components/datasets/DatasetWizard/WizardContext.tsx)**:
> - Loads workspace defaults on wizard mount
> - `convertDefaultsToParsing()` - Convert API defaults to ParsingOptions
> - `APPLY_DEFAULTS` action to set parsing from workspace
> - `workspaceDefaults` state exposed via context
> - `reloadDefaults()` function to refresh from API
> - Reset action uses workspace defaults when available

---

## Phase 6: Developer Mode Features

**Priority**: ðŸŸ¢ Low
**Estimated Effort**: Small (2-3 days)

### 6.1 Synthetic Dataset Generation

In developer mode, Dashboard quick actions include generating synthetic datasets:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Developer Quick Start                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Generate Synthetic Dataset:                 â”‚
â”‚                                             â”‚
â”‚ â—‹ Regression (250 samples)                  â”‚
â”‚ â—‹ Regression (2500 samples)                 â”‚
â”‚ â—‹ Classification (300 samples, 3 classes)   â”‚
â”‚ â—‹ Custom...                                 â”‚
â”‚                                             â”‚
â”‚ Options:                                    â”‚
â”‚ [âœ“] Include repetitions                     â”‚
â”‚ [âœ“] Include metadata                        â”‚
â”‚ [âœ“] Add noise                               â”‚
â”‚                                             â”‚
â”‚ [Generate & Load]                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 nirs4all.generate Integration

Use nirs4all's synthesis tools:

```python
# Backend: dashboard.py or datasets.py
@router.post("/datasets/generate-synthetic")
async def generate_synthetic(
    task_type: str = "regression",
    n_samples: int = 500,
    n_features: int = 256,
    include_repetitions: bool = True,
    include_metadata: bool = True,
    noise_level: float = 0.05,
):
    import nirs4all

    if task_type == "regression":
        dataset = nirs4all.generate.regression(
            n_samples=n_samples,
            n_features=n_features,
            ...
        )
    elif task_type == "classification":
        dataset = nirs4all.generate.classification(
            n_samples=n_samples,
            n_features=n_features,
            n_classes=3,
            ...
        )

    # Save to workspace as temporary dataset
    # Return dataset info for immediate use
```

### 6.3 Tasks

- [x] **T6.1**: Add developer mode toggle in Settings âœ… *Phase 5 - Now uses DeveloperModeContext*
- [x] **T6.2**: Conditional UI for developer mode features âœ… *DeveloperQuickStart card in Dashboard*
- [x] **T6.3**: API: `/api/datasets/generate-synthetic` âœ… *Full implementation with nirs4all.generate*
- [x] **T6.4**: Dashboard: Synthetic data generation card âœ… *DeveloperQuickStart component*
- [x] **T6.5**: Options for repetitions, metadata, noise âœ… *Included in GenerateSyntheticRequest*
- [x] **T6.6**: Auto-link generated dataset to workspace âœ… *auto_link parameter*

> **Phase 6 Implementation Summary** (2026-01-07):
>
> **Backend (api/datasets.py)**:
> - `GenerateSyntheticRequest` - Full request model with options:
>   - task_type: regression, binary_classification, multiclass_classification
>   - n_samples, complexity, n_classes, target_range, train_ratio
>   - include_metadata, include_repetitions, noise_level
>   - add_batch_effects, n_batches, wavelength_range
>   - name (optional), auto_link (default true)
> - `GenerateSyntheticResponse` - Response with dataset info and summary
> - `POST /datasets/generate-synthetic` - Generate synthetic dataset
>   - Uses nirs4all.generate.regression() or classification()
>   - Exports to workspace/datasets/synthetic folder
>   - Auto-links to workspace if requested
> - `GET /datasets/synthetic-presets` - Pre-configured generation options
>   - Regression (Small/Medium/Large)
>   - Binary/Multiclass Classification
>   - Complex Realistic (with noise and batch effects)
> - `SyntheticPresetInfo` - Preset configuration model
>
> **Frontend Context (src/context/DeveloperModeContext.tsx)**:
> - `DeveloperModeProvider` - App-wide developer mode state
> - `useDeveloperMode()` - Full hook with toggle, setDeveloperMode, refresh
> - `useIsDeveloperMode()` - Simple boolean check hook
> - Persists to workspace settings via API
>
> **Frontend Component (src/components/dashboard/DeveloperQuickStart.tsx)**:
> - Preset grid for quick selection (4 presets visible)
> - Custom configuration collapsible section
>   - Task type selector
>   - Sample count slider (100-5000)
>   - Complexity selector
>   - Noise level slider
>   - Toggles for metadata, batch effects, auto-link
>   - Custom name input
> - Generate & Load button with loading state
> - Success/error feedback with animation
> - Auto-navigates to datasets page on success
>
> **Frontend Integration (src/pages/Dashboard.tsx)**:
> - Conditionally renders DeveloperQuickStart when dev mode enabled
> - Uses useIsDeveloperMode() from context
>
> **Types (src/types/settings.ts)**:
> - `GenerateSyntheticRequest` - Request parameters
> - `GeneratedDatasetSummary` - Generation summary
> - `GenerateSyntheticResponse` - API response
> - `SyntheticPreset` - Preset configuration
> - `DEFAULT_SYNTHETIC_CONFIG` - Default form values
>
> **API Client (src/api/client.ts)**:
> - `generateSyntheticDataset()` - Generate synthetic data
> - `getSyntheticPresets()` - Get preset configurations
>
> **Provider Setup (src/main.tsx)**:
> - Added `DeveloperModeProvider` wrapping App component

---

## Technical Considerations

### API Changes Summary

| Endpoint | Method | Description | Phase |
|----------|--------|-------------|-------|
| `/api/datasets/preview` | POST | Preview parsed data | 1 |
| `/api/datasets/detect-files` | POST | Scan folder for data files | 1 |
| `/api/datasets/detect-format` | POST | Detect file format | 1 |
| `/api/datasets/{id}/verify` | POST | Verify dataset hash | 2 |
| `/api/datasets/{id}/relink` | POST | Update dataset path | 2 |
| `/api/workspace/stats` | GET | Workspace space usage | 5 |
| `/api/workspace/clean-cache` | POST | Clean temporary files and cache | 5 |
| `/api/workspace/backup` | POST | Create workspace backup | 5 |
| `/api/workspace/settings` | GET/PUT | Workspace settings | 5 |
| `/api/workspace/data-defaults` | GET/PUT | Data loading defaults | 5 |
| `/api/datasets/generate-synthetic` | POST | Generate synthetic data | 6 |
| `/api/datasets/synthetic-presets` | GET | Get synthetic data presets | 6 |

### Schema Changes

**Dataset in workspace.json**:
```json
{
  "id": "uuid",
  "name": "wheat_protein",
  "path": "/data/wheat",
  "hash": "a3f7c2e9",
  "last_verified": "2025-01-07T10:30:00Z",
  "version": 1,
  "config": {
    "train_x": "train_x.csv",
    "train_y": "train_y.csv",
    "train_x_params": {
      "delimiter": ";",
      "header_unit": "nm",
      "signal_type": "reflectance"
    },
    "global_params": {
      "na_policy": "drop"
    }
  },
  "targets": [
    {"column": "protein", "type": "regression", "unit": "%"},
    {"column": "moisture", "type": "regression", "unit": "%"}
  ],
  "default_target": "protein",
  "num_samples": 1250,
  "num_features": 2048,
  "status": "current",
  "group": "project_wheat"
}
```

### Component Structure

```
src/components/datasets/
â”œâ”€â”€ AddDatasetModal.tsx      â†’ DEPRECATED (replace with wizard)
â”œâ”€â”€ DatasetWizard/
â”‚   â”œâ”€â”€ index.tsx            # Wizard container âœ…
â”‚   â”œâ”€â”€ WizardContext.tsx    # State management âœ… (Phase 5: workspace defaults)
â”‚   â”œâ”€â”€ SourceStep.tsx       # Step 1 âœ…
â”‚   â”œâ”€â”€ FileMappingStep.tsx  # Step 2 âœ…
â”‚   â”œâ”€â”€ ParsingStep.tsx      # Step 3 âœ…
â”‚   â”œâ”€â”€ TargetsStep.tsx      # Step 4 âœ… (Phase 3 enhanced)
â”‚   â””â”€â”€ PreviewStep.tsx      # Step 5 âœ…
â”œâ”€â”€ DatasetCard.tsx          # Enhanced with status badge âœ… (Phase 3: multi-target display)
â”œâ”€â”€ DatasetStatusBadge.tsx   # Version status indicator âœ…
â”œâ”€â”€ RelinkDialog.tsx         # Path update dialog âœ…
â”œâ”€â”€ RefreshDialog.tsx        # Change summary dialog âœ…
â”œâ”€â”€ TargetSelector.tsx       # Reusable target selector âœ… (Phase 3)
â””â”€â”€ index.ts                 # Barrel exports âœ…

src/components/settings/     # Phase 5 âœ…
â”œâ”€â”€ WorkspaceStats.tsx       # Space usage with progress bars âœ…
â”œâ”€â”€ DataLoadingDefaultsForm.tsx  # Parsing defaults form âœ…
â””â”€â”€ index.ts                 # Barrel exports âœ…

src/components/pipeline-editor/
â”œâ”€â”€ DatasetBinding.tsx       # Dataset binding dropdown âœ… (Phase 4)
â”œâ”€â”€ contexts/
â”‚   â””â”€â”€ DatasetBindingContext.tsx  # Binding context provider âœ… (Phase 4)
â””â”€â”€ core/tree-node/
    â””â”€â”€ StepShapeIndicator.tsx     # Shape display component âœ… (Phase 4)

src/components/dashboard/     # Phase 6 âœ…
â”œâ”€â”€ DeveloperQuickStart.tsx  # Synthetic data generation card âœ…
â””â”€â”€ index.ts                 # Updated with export âœ…

src/context/                  # Phase 6 âœ…
â””â”€â”€ DeveloperModeContext.tsx # App-wide developer mode state âœ…

src/hooks/
â”œâ”€â”€ useDatasetBinding.ts     # Binding state management âœ… (Phase 4)
â””â”€â”€ useShapePropagation.ts   # Shape calculation hook âœ… (Phase 4)

src/pages/
â”œâ”€â”€ Dashboard.tsx            # Conditional DeveloperQuickStart âœ… (Phase 6)
â””â”€â”€ Settings.tsx             # Reorganized with tabs âœ… (Phase 5, uses context Phase 6)

src/types/
â””â”€â”€ settings.ts              # Workspace & settings types âœ… (Phase 5, Phase 6 additions)
```

---

## Dependencies

### Phase Dependencies

```
Phase 1 (Wizard) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         âœ…                â†“                                           â†“
Phase 2 (Versioning) â”€â”€â”€â”€â”€â”´â”€â”€â†’ Phase 3 (Multi-Target) â”€â”€â†’ Phase 4 (Pipeline)
         âœ…                              âœ…                      âœ…
                                                                      â†“
Phase 5 (Settings) â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         âœ…                â†“
Phase 6 (Dev Mode) â†â”€â”€â”€â”€â”€â”€â”˜
         âœ…
```

### External Dependencies

- **nirs4all**: All data loading functionality
- **pywebview**: Native file dialogs (desktop mode)
- **recharts**: Data preview charts
- **shadcn/ui**: UI components

---

## Success Metrics

| Metric | Target | Current |
|--------|--------|---------|
| Dataset loading success rate | > 95% | TBD |
| Average wizard completion time | < 3 minutes | TBD |
| User confusion (support tickets) | < 5% of users | TBD |
| Dataset format support coverage | 100% of nirs4all formats | ~80% |

---

## Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 0.1 | 2025-01-07 | Copilot | Initial draft from UI_SPECIFICATION annotations |
| 0.2 | 2025-01-07 | Copilot | Phase 1 marked complete, Phase 2 fully implemented |
| 0.3 | 2025-01-07 | Copilot | Phase 3 Multi-Target Support complete |
| 0.4 | 2025-01-08 | Copilot | Phase 4 Pipeline Integration complete |
| 0.5 | 2026-01-07 | Copilot | Phase 5 Workspace & Settings complete: stats, clean cache, backup, data loading defaults, Settings page reorganization |
| 1.0 | 2026-01-07 | Copilot | Phase 6 Developer Mode Features complete: synthetic data generation API, DeveloperQuickStart dashboard card, DeveloperModeContext, presets system. All phases complete. |
